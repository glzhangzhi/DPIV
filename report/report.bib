
@misc{zhang_unsupervised_2020,
	title = {Unsupervised Learning of Particle Image Velocimetry},
	url = {http://arxiv.org/abs/2007.14487},
	abstract = {Particle Image Velocimetry ({PIV}) is a classical ﬂow estimation problem which is widely considered and utilised, especially as a diagnostic tool in experimental ﬂuid dynamics and the remote sensing of environmental ﬂows. Recently, the development of deep learning based methods has inspired new approaches to tackle the {PIV} problem. These supervised learning based methods are driven by large volumes of data with ground truth training information. However, it is diﬃcult to collect reliable ground truth data in large-scale, real-world scenarios. Although synthetic datasets can be used as alternatives, the gap between the training set-ups and real-world scenarios limits applicability. We present here what we believe to be the ﬁrst work which takes an unsupervised learning based approach to tackle {PIV} problems. The proposed approach is inspired by classic optical ﬂow methods. Instead of using ground truth data, we make use of photometric loss between two consecutive image frames, consistency loss in bidirectional ﬂow estimates and spatial smoothness loss to construct the total unsupervised loss function. The approach shows signiﬁcant potential and advantages for ﬂuid ﬂow estimation. Results presented here demonstrate that our method outputs competitive results compared with classical {PIV} methods as well as supervised learning based methods for a broad {PIV} dataset, and even outperforms these existing approaches in some diﬃcult ﬂow cases. Codes and trained models are available at https://github.com/erizmr/{UnLiteFlowNet}-{PIV}.},
	number = {{arXiv}:2007.14487},
	publisher = {{arXiv}},
	author = {Zhang, Mingrui and Piggott, Matthew D.},
	urldate = {2023-05-03},
	date = {2020-07-28},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2007.14487 [cs, eess]},
	keywords = {Unsupervised Learning, Convolutional Neural Network, readed},
	file = {Zhang 和 Piggott - 2020 - Unsupervised Learning of Particle Image Velocimetr.pdf:C\:\\Users\\Administrator\\Zotero\\storage\\M3LF4ICU\\Zhang 和 Piggott - 2020 - Unsupervised Learning of Particle Image Velocimetr.pdf:application/pdf},
}

@misc{sankaewtong_learning_2022,
	title = {Learning to swim efficiently in a nonuniform flow field},
	url = {http://arxiv.org/abs/2212.11482},
	abstract = {Microswimmers can acquire information on the surrounding fluid by sensing mechanical queues. They can then navigate in response to these signals. We analyse this navigation by combining deep reinforcement learning with direct numerical simulations to resolve the hydrodynamics. We study how local and non-local information can be used to train a swimmer to achieve particular swimming tasks in a non-uniform flow field, in particular a zig-zag shear flow. The swimming tasks are (1) learning how to swim in the vorticity direction, (2) the shear-gradient direction, and (3) the shear flow direction. We find that access to lab frame information on the swimmer's instantaneous orientation is all that is required in order to reach the optimal policy for (1,2). However, information on both the translational and rotational velocities seem to be required to achieve (3). Inspired by biological microorganisms we also consider the case where the swimmers sense local information, i.e. surface hydrodynamic forces, together with a signal direction. This might correspond to gravity or, for micro-organisms with light sensors, a light source. In this case, we show that the swimmer can reach a comparable level of performance as a swimmer with access to lab frame variables. We also analyse the role of different swimming modes, i.e. pusher, puller, and neutral swimmers.},
	number = {{arXiv}:2212.11482},
	publisher = {{arXiv}},
	author = {Sankaewtong, Krongtum and Molina, John J. and Turner, Matthew S. and Yamamoto, Ryoichi},
	urldate = {2023-05-03},
	date = {2022-12-21},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2212.11482 [cond-mat, physics:physics]},
	file = {Sankaewtong 等 - 2022 - Learning to swim efficiently in a nonuniform flow .pdf:C\:\\Users\\Administrator\\Zotero\\storage\\3C5MT8MW\\Sankaewtong 等 - 2022 - Learning to swim efficiently in a nonuniform flow .pdf:application/pdf},
}

@misc{zheng_deep_2023,
	title = {Deep Learning for Event-based Vision: A Comprehensive Survey and Benchmarks},
	url = {http://arxiv.org/abs/2302.08890},
	shorttitle = {Deep Learning for Event-based Vision},
	abstract = {Event cameras are bio-inspired sensors that capture the per-pixel intensity changes asynchronously and produce event streams encoding the time, pixel position, and polarity (sign) of the intensity changes. Event cameras possess a myriad of advantages over canonical frame-based cameras, such as high temporal resolution, high dynamic range, low latency, etc. Being capable of capturing information in challenging visual conditions, event cameras have the potential to overcome the limitations of frame-based cameras in the computer vision and robotics community. In very recent years, deep learning ({DL}) has been brought to this emerging ﬁeld and inspired active research endeavors in mining its potential. However, the technical advances still remain unknown, thus making it urgent and necessary to conduct a systematic overview. To this end, we conduct the ﬁrst yet comprehensive and in-depth survey, with a focus on the latest developments of {DL} techniques for event-based vision. We ﬁrst scrutinize the typical event representations with quality enhancement methods as they play a pivotal role as inputs to the {DL} models. We then provide a comprehensive taxonomy for existing {DL}-based methods by structurally grouping them into two major categories: 1) image reconstruction and restoration; 2) event-based scene understanding 3D vision. Importantly, we conduct benchmark experiments for the existing methods in some representative research directions (e.g., object recognition and optical ﬂow estimation) to identify some critical insights and problems. Finally, we make important discussions regarding the challenges and provide new perspectives for motivating future research studies.},
	number = {{arXiv}:2302.08890},
	publisher = {{arXiv}},
	author = {Zheng, Xu and Liu, Yexin and Lu, Yunfan and Hua, Tongyan and Pan, Tianbo and Zhang, Weiming and Tao, Dacheng and Wang, Lin},
	urldate = {2023-05-03},
	date = {2023-02-17},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2302.08890 [cs]},
	file = {Zheng 等 - 2023 - Deep Learning for Event-based Vision A Comprehens.pdf:C\:\\Users\\Administrator\\Zotero\\storage\\TZLLLR9S\\Zheng 等 - 2023 - Deep Learning for Event-based Vision A Comprehens.pdf:application/pdf},
}

@article{gao_robust_2021,
	title = {A robust single-pixel particle image velocimetry based on fully convolutional networks with cross-correlation embedded},
	volume = {33},
	issn = {1070-6631, 1089-7666},
	url = {http://arxiv.org/abs/2111.00395},
	doi = {10.1063/5.0077146},
	abstract = {Particle image velocimetry ({PIV}) is essential in experimental fluid dynamics. In the current work, we propose a new velocity field estimation paradigm, which achieves a synergetic combination of the deep learning method and the traditional cross-correlation method. Specifically, the deep learning method is used to optimize and correct a coarse velocity guess to achieve a super-resolution calculation. And the cross-correlation method provides the initial velocity field based on a coarse correlation with a large interrogation window. As a reference, the coarse velocity guess helps with improving the robustness of the proposed algorithm. This fully convolutional network with embedded cross-correlation is named as {CC}-{FCN}. {CC}-{FCN} has two types of input layers, one is for the particle images, and the other is for the initial velocity field calculated using cross-correlation with a coarse resolution. Firstly, two pyramidal modules extract features of particle images and initial velocity field respectively. Then the fusion module appropriately fuses these features. Finally, {CC}-{FCN} achieves the super-resolution calculation through a series of deconvolution layers to obtain the single-pixel velocity field. As the supervised learning strategy is considered, synthetic data sets including ground-truth fluid motions are generated to train the network parameters. Synthetic and real experimental {PIV} data sets are used to test the trained neural network in terms of accuracy, precision, spatial resolution and robustness. The test results show that these attributes of {CC}-{FCN} are further improved compared with those of other tested {PIV} algorithms. The proposed model could therefore provide competitive and robust estimations for {PIV} experiments.},
	pages = {127125},
	number = {12},
	journaltitle = {Physics of Fluids},
	shortjournal = {Physics of Fluids},
	author = {Gao, Qi and Lin, Hongtao and Tu, Han and Zhu, Haoran and Wei, Runjie and Zhang, Guoping and Shao, Xueming},
	urldate = {2023-05-03},
	date = {2021-12},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2111.00395 [physics]},
	file = {Gao 等 - 2021 - A robust single-pixel particle image velocimetry b.pdf:C\:\\Users\\Administrator\\Zotero\\storage\\N2HY4JNP\\Gao 等 - 2021 - A robust single-pixel particle image velocimetry b.pdf:application/pdf},
}

@misc{wang_superresolution_2022,
	title = {Superresolution Reconstruction of Single Image for Latent features},
	url = {http://arxiv.org/abs/2211.12845},
	abstract = {In recent years, Deep Learning has shown good results in the Single Image Superresolution Reconstruction ({SISR}) task, thus becoming the most widely used methods in this ﬁeld. The {SISR} task is a typical problem solving task where there may be an inﬁnite number of High-resolution ({HR}) images corresponding to a single Low-resolution ({LR}) image. Therefore, it is often challenging to meet the requirements of high-quality sampling, fast sampling, and diversity of details and texture after Sampling simultaneously in a {SISR} task.It leads to model collapse, lack of details and texture features after Sampling, and too long Sampling time in {HR} image reconstruction methods. This paper proposes Denoising Diffusion Probabilistic model for Latent features ({LDDPM}) to solve these problems. Firstly, a Conditional Encoder is designed to effectively encode {LR} images, thereby reducing the solution space of reconstructed images to improve the performance of reconstructed images. Then, the Normalized Flow and Multi-modal adversarial training are used to model the denoising distribution with complex Multimodal distribution so that the Generative Modeling ability of the model can be improved with a small number of Sampling steps. Experimental results on mainstream datasets demonstrate that our proposed model reconstructs more realistic {HR} images and obtains better {PSNR} and {SSIM} performance compared to existing {SISR} tasks, thus providing a new idea for {SISR} tasks.},
	number = {{arXiv}:2211.12845},
	publisher = {{arXiv}},
	author = {Wang, Xin and Yan, Jing-Ke and Cai, Jing-Ye and Deng, Jian-Hua and Qin, Qin and Wang, Qin and Xiao, Heng and Cheng, Yao and Ye, Peng-Fei},
	urldate = {2023-05-03},
	date = {2022-11-25},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2211.12845 [cs, eess]},
	file = {Wang 等 - 2022 - Superresolution Reconstruction of Single Image for.pdf:C\:\\Users\\Administrator\\Zotero\\storage\\SSFL8HB8\\Wang 等 - 2022 - Superresolution Reconstruction of Single Image for.pdf:application/pdf},
}

@misc{cremades_explaining_2023,
	title = {Explaining wall-bounded turbulence through deep learning},
	url = {http://arxiv.org/abs/2302.01250},
	abstract = {Despite its great scientific and technological importance, wall-bounded turbulence is an unresolved problem that requires new perspectives to be tackled. One of the key strategies has been to study interactions among the coherent structures in the flow. Such interactions are explored in this study for the first time using an explainable deep-learning method. The instantaneous velocity field in a turbulent channel is used to predict the velocity field in time through a convolutional neural network. Based on the predicted flow, we assess the importance of each structure for this prediction using the game-theoretic algorithm of {SHapley} Additive {exPlanations} ({SHAP}). This work provides results in agreement with previous observations in the literature and extends them by quantifying the importance of the Reynolds-stress structures, finding a connection between these structures and the dynamics of the flow. The process, based on deep-learning explainability, has the potential to shed light on numerous fundamental phenomena of wall-bounded turbulence, including the objective definition of new types of flow structures.},
	number = {{arXiv}:2302.01250},
	publisher = {{arXiv}},
	author = {Cremades, Andres and Hoyas, Sergio and Quintero, Pedro and Lellep, Martin and Linkmann, Moritz and Vinuesa, Ricardo},
	urldate = {2023-05-03},
	date = {2023-04-06},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2302.01250 [physics]},
	file = {Cremades 等 - 2023 - Explaining wall-bounded turbulence through deep le.pdf:C\:\\Users\\Administrator\\Zotero\\storage\\T2AA2K6U\\Cremades 等 - 2023 - Explaining wall-bounded turbulence through deep le.pdf:application/pdf},
}

@article{lee_diffeomorphic_2022,
	title = {Diffeomorphic Particle Image Velocimetry},
	volume = {71},
	issn = {0018-9456, 1557-9662},
	url = {http://arxiv.org/abs/2108.07438},
	doi = {10.1109/TIM.2021.3132999},
	abstract = {The existing particle image velocimetry ({PIV}) do not consider the curvature effect of the non-straight particle trajectory, because it seems to be impossible to obtain the curvature information from a pair of particle images. As a result, the computed vector underestimates the real velocity due to the straight-line approximation, that further causes a systematic error for the {PIV} instrument. In this work, the particle curved trajectory between two recordings is firstly explained with the streamline segment of a steady flow (diffeomorphic transformation) instead of a single vector, and this idea is termed as diffeomorphic {PIV}. Specifically, a deformation field is introduced to describe the particle displacement, i.e., we try to find the optimal velocity field, of which the corresponding deformation vector field agrees with the particle displacement. Because the variation of the deformation function can be approximated with the variation of the velocity function, the diffeomorphic {PIV} can be implemented as iterative {PIV}. That says, the diffeomorphic {PIV} warps the images with deformation vector field instead of the velocity, and keeps the rest as same as iterative {PIVs}. Two diffeomorphic deformation schemes -- forward diffeomorphic deformation interrogation ({FDDI}) and central diffeomorphic deformation interrogation ({CDDI}) -- are proposed. Tested on synthetic images, the {FDDI} achieves significant accuracy improvement across different one-pass displacement estimators (cross-correlation, optical flow, deep learning flow). Besides, the results on three real {PIV} image pairs demonstrate the non-negligible curvature effect for {CDI}-based {PIV}, and our {FDDI} provides larger velocity estimation (more accurate) in the fast curvy streamline areas. The accuracy improvement of the combination of {FDDI} and accurate dense estimator means that our diffeomorphic {PIV} paves a new way for complex flow measurement.},
	pages = {1--10},
	journaltitle = {{IEEE} Transactions on Instrumentation and Measurement},
	shortjournal = {{IEEE} Trans. Instrum. Meas.},
	author = {Lee, Yong and Mei, Shuang},
	urldate = {2023-05-03},
	date = {2022},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2108.07438 [cs, eess]},
	file = {Lee 和 Mei - 2022 - Diffeomorphic Particle Image Velocimetry.pdf:C\:\\Users\\Administrator\\Zotero\\storage\\CZ8QGRAW\\Lee 和 Mei - 2022 - Diffeomorphic Particle Image Velocimetry.pdf:application/pdf},
}

@misc{yang_denoising_2023,
	title = {A Denoising Diffusion Model for Fluid Field Prediction},
	url = {http://arxiv.org/abs/2301.11661},
	abstract = {We propose a novel denoising diffusion generative model for predicting nonlinear ﬂuid ﬁelds named {FluidDiff}. By performing a diffusion process, the model is able to learn a complex representation of the high-dimensional dynamic system, and then Langevin sampling is used to generate predictions for the ﬂow state under speciﬁed initial conditions. The model is trained with ﬁnite, discrete ﬂuid simulation data. We demonstrate that our model has the capacity to model the distribution of simulated training data and that it gives accurate predictions on the test data. Without encoded prior knowledge of the underlying physical system, it shares competitive performance with other deep learning models for ﬂuid prediction, which is promising for investigation on new computational ﬂuid dynamics methods.},
	number = {{arXiv}:2301.11661},
	publisher = {{arXiv}},
	author = {Yang, Gefan and Sommer, Stefan},
	urldate = {2023-05-03},
	date = {2023-01-30},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2301.11661 [physics]},
	file = {Yang 和 Sommer - 2023 - A Denoising Diffusion Model for Fluid Field Predic.pdf:C\:\\Users\\Administrator\\Zotero\\storage\\I8XZA4RX\\Yang 和 Sommer - 2023 - A Denoising Diffusion Model for Fluid Field Predic.pdf:application/pdf},
}

@misc{ozbay_fr3d_2023,
	title = {{FR}3D: Three-dimensional Flow Reconstruction and Force Estimation for Unsteady Flows Around Arbitrary Bluff Bodies via Conformal Mapping Aided Convolutional Autoencoders},
	url = {http://arxiv.org/abs/2302.01802},
	shorttitle = {{FR}3D},
	abstract = {In many practical ﬂuid dynamics experiments, measuring variables such as velocity and pressure is possible only at a limited number of sensor locations, or for a few two-dimensional planes in the ﬂow. However, knowledge of the full ﬁelds is necessary to understand the dynamics of many ﬂows. Deep learning reconstruction of full ﬂow ﬁelds from sparse measurements has recently garnered signiﬁcant research interest, as a way of overcoming this limitation. This task is referred to as the ﬂow reconstruction ({FR}) task. In the present study, we propose a convolutional autoencoder based neural network model, dubbed {FR}3D, which enables {FR} to be carried out for three-dimensional ﬂows around extruded 3D objects with arbitrary cross-sections. An innovative mapping approach, whereby multiple ﬂuid domains are mapped to an annulus, enables {FR}3D to generalize its performance to objects not encountered during training. We conclusively demonstrate this generalization capability using a dataset composed of 80 training and 20 testing geometries, all randomly generated. We show that the {FR}3D model reconstructs pressure and velocity components with a few percentage points of error. Additionally, using these predictions, we accurately estimate the Q-criterion ﬁelds as well lift and drag forces on the geometries.},
	number = {{arXiv}:2302.01802},
	publisher = {{arXiv}},
	author = {Özbay, Ali Girayhan and Laizet, Sylvain},
	urldate = {2023-05-03},
	date = {2023-02-03},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2302.01802 [physics]},
	keywords = {68T07, 76F65},
	file = {Özbay 和 Laizet - 2023 - FR3D Three-dimensional Flow Reconstruction and Fo.pdf:C\:\\Users\\Administrator\\Zotero\\storage\\4K4AC36S\\Özbay 和 Laizet - 2023 - FR3D Three-dimensional Flow Reconstruction and Fo.pdf:application/pdf},
}

@article{cai_flow_2021,
	title = {Flow over an espresso cup: Inferring 3D velocity and pressure fields from tomographic background oriented schlieren videos via physics-informed neural networks},
	volume = {915},
	issn = {0022-1120, 1469-7645},
	url = {http://arxiv.org/abs/2103.02807},
	doi = {10.1017/jfm.2021.135},
	shorttitle = {Flow over an espresso cup},
	abstract = {Tomographic background oriented schlieren (Tomo-{BOS}) imaging measures density or temperature fields in 3D using multiple camera {BOS} projections, and is particularly useful for instantaneous flow visualizations of complex fluid dynamics problems. We propose a new method based on physics-informed neural networks ({PINNs}) to infer the full continuous 3D velocity and pressure fields from snapshots of 3D temperature fields obtained by Tomo-{BOS} imaging. {PINNs} seamlessly integrate the underlying physics of the observed fluid flow and the visualization data, hence enabling the inference of latent quantities using limited experimental data. In this hidden fluid mechanics paradigm, we train the neural network by minimizing a loss function composed of a data mismatch term and residual terms associated with the coupled Navier-Stokes and heat transfer equations. We first quantify the accuracy of the proposed method based on a 2D synthetic data set for buoyancy-driven flow, and subsequently apply it to the Tomo-{BOS} data set, where we are able to infer the instantaneous velocity and pressure fields of the flow over an espresso cup based only on the temperature field provided by the Tomo-{BOS} imaging. Moreover, we conduct an independent {PIV} experiment to validate the {PINN} inference for the unsteady velocity field at a center plane. To explain the observed flow physics, we also perform systematic {PINN} simulations at different Reynolds and Richardson numbers and quantify the variations in velocity and pressure fields. The results in this paper indicate that the proposed deep learning technique can become a promising direction in experimental fluid mechanics.},
	pages = {A102},
	journaltitle = {Journal of Fluid Mechanics},
	shortjournal = {J. Fluid Mech.},
	author = {Cai, Shengze and Wang, Zhicheng and Fuest, Frederik and Jeon, Young-Jin and Gray, Callum and Karniadakis, George Em},
	urldate = {2023-05-03},
	date = {2021-05-25},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2103.02807 [physics]},
	file = {Cai 等 - 2021 - Flow over an espresso cup Inferring 3D velocity a.pdf:C\:\\Users\\Administrator\\Zotero\\storage\\FZFZAV96\\Cai 等 - 2021 - Flow over an espresso cup Inferring 3D velocity a.pdf:application/pdf},
}

@misc{li_numerical_2023,
	title = {A numerical simulation method of fish adaption behavior based on deep reinforcement learning and fluid-structure coupling-realization of some lateral line functions},
	url = {http://arxiv.org/abs/2301.10085},
	abstract = {Improving the numerical method of ﬁsh autonomous swimming behavior in complex environments is of great signiﬁcance to the optimization of bionic controller, the design of ﬁsh passing facilities and the study of ﬁsh behavior. This work has built a ﬁsh autonomous swimming simulation platform, which adapts the high-precision immersed boundary–Lattice Boltzmann method ({IB}-{LBM}) to simulate the dynamic process of the interaction between the ﬁsh and the ﬂow ﬁeld in real time, and realizes the ﬁsh brain motion control through the Soft Actor-Critic ({SAC}) deep reinforcement learning algorithm. More importantly, in view of the poor generalization of the existing simulation platform, a method to simulate the ﬁsh’s lateral line function is proposed. By adding the Lateral-line machine and designing the Macroaction system, the intelligent ﬁsh initially has the ability to recognize, classify, memorize and transplant the corresponding swimming strategy in the unsteady ﬁeld. Using this method, the training and simulation of point-to-point predation swimming and Ka´ma´n-gait test under diﬀerent inlet velocities are carried out. In the example of point-to-point predation swimming, the ﬁsh in random position can adjust the swimming posture and speed autonomously to catch the fast moving food, and has a certain prediction ability on the movement trajectory of the food. In the Ka´ma´n-gait test, the trained ﬁsh are placed in three diﬀerent Ka´ma´n-gait ﬂow ﬁelds, to study its ability to recognize the ﬂow ﬁeld and select swimming strategies through experience. The results of numerical experiments show that, comparing with the other value function networks, the {SAC} algorithm based on maximum entropy {RL} framework and oﬀpolicy has more advantages in convergence speed and training eﬃciency when simulating ﬁsh brain decision-making. The use of the Lateral-line Machine and Macro-action system can avoid the waste of experience and improve the adaptability of intelligent ﬁsh in the new complex ﬂow ﬁeld environment.},
	number = {{arXiv}:2301.10085},
	publisher = {{arXiv}},
	author = {Li, Tao and Zhang, Chunze and Peng, Peiyi and Hou, Ji and Zhou, Qin and Ma, Qian},
	urldate = {2023-05-03},
	date = {2023-01-24},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2301.10085 [physics]},
	file = {Li 等 - 2023 - A numerical simulation method of fish adaption beh.pdf:C\:\\Users\\Administrator\\Zotero\\storage\\YY3YGELI\\Li 等 - 2023 - A numerical simulation method of fish adaption beh.pdf:application/pdf},
}

@misc{yousif_physics-guided_2023,
	title = {Physics-guided deep reinforcement learning for flow field denoising},
	url = {http://arxiv.org/abs/2302.09559},
	abstract = {A multi-agent deep reinforcement learning ({DRL})-based model is presented in this study to reconstruct ﬂow ﬁelds from noisy data. A combination of the reinforcement learning with pixel-wise rewards ({PixelRL}), physical constraints represented by the momentum equation and the pressure Poisson equation and the known boundary conditions is utilised to build a physics-guided deep reinforcement learning ({PGDRL}) model that can be trained without the target training data. In the {PGDRL} model, each agent corresponds to a point in the ﬂow ﬁeld and it learns an optimal strategy for choosing pre-deﬁned actions. The proposed model is efﬁcient considering the visualisation of the action map and the interpretation of the model performance. The performance of the model is tested by utilising synthetic direct numerical simulation ({DNS})-based noisy data and experimental data obtained by particle image velocimetry ({PIV}). Qualitative and quantitative results show that the model can reconstruct the ﬂow ﬁelds and reproduce the statistics and the spectral content with commendable accuracy. These results demonstrate that the combination of {DRL}-based models and the known physics of the ﬂow ﬁelds can potentially help solve complex ﬂow reconstruction problems, which can result in a remarkable reduction in the experimental and computational costs.},
	number = {{arXiv}:2302.09559},
	publisher = {{arXiv}},
	author = {Yousif, Mustafa Z. and Zhang, Meng and Yang, Yifan and Zhou, Haifeng and Yu, Linqi and Lim, {HeeChang}},
	urldate = {2023-05-03},
	date = {2023-02-19},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2302.09559 [physics]},
	file = {Yousif 等 - 2023 - Physics-guided deep reinforcement learning for flo.pdf:C\:\\Users\\Administrator\\Zotero\\storage\\2DG8P9P4\\Yousif 等 - 2023 - Physics-guided deep reinforcement learning for flo.pdf:application/pdf},
}

@misc{zheng_quantum_2022,
	title = {A quantum neural network with efficient optimization and interpretability},
	url = {http://arxiv.org/abs/2211.05793},
	abstract = {As the quantum counterparts to the classical artificial neural networks underlying widespread machine-learning applications, unitary-based quantum neural networks are active in various fields of quantum computation. Despite the potential, their developments have been hampered by the elevated cost of optimizations and difficulty in realizations. Here, we propose a quantum neural network in the form of fermion models whose physical properties, such as the local density of states and conditional conductance, serve as outputs, and establish an efficient optimization comparable to back-propagation. In addition to competitive accuracy on challenging classical machine-learning benchmarks, our fermion quantum neural network performs machine learning on quantum systems with high precision and without preprocessing. The quantum nature also brings various other advantages, e.g., quantum correlations entitle networks with more general and local connectivity facilitating numerical simulations and experimental realizations, as well as novel perspectives to address the vanishing gradient problem long plaguing deep networks. We also demonstrate the applications of our quantum toolbox, such as quantum-entanglement analysis, for interpretable machine learning, including training dynamics, decision logic flow, and criteria formulation.},
	number = {{arXiv}:2211.05793},
	publisher = {{arXiv}},
	author = {Zheng, Pei-Lin and Wang, Jia-Bao and Zhang, Yi},
	urldate = {2023-05-03},
	date = {2022-11-10},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2211.05793 [cond-mat, physics:quant-ph]},
	file = {Zheng 等 - 2022 - A quantum neural network with efficient optimizati.pdf:C\:\\Users\\Administrator\\Zotero\\storage\\K5AK9UIN\\Zheng 等 - 2022 - A quantum neural network with efficient optimizati.pdf:application/pdf},
}

@misc{mallik_parametric_2023,
	title = {A parametric level set method with convolutional encoder-decoder network for shape optimization with fluid flow},
	url = {http://arxiv.org/abs/2301.05597},
	abstract = {In this article, we present a new data-driven shape optimization approach for implicit hydrofoil morphing via a polynomial perturbation of parametric level set representation. Without introducing any change in topology, the hydrofoil morphing is achieved by six shape design variables associated with the amplitude and shape of the perturbed displacements. The proposed approach has three to four times lower design variables than shape optimization via free-form deformation techniques and almost two orders lower design variables compared to topology optimization via traditional parametric level sets. Using the fixed Cartesian level set mesh, we also integrate deep convolutional encoder-decoder networks as a surrogate of high-fidelity Reynolds-averaged Navier-Stokes ({RANS}) simulations for learning the flow field around hydrofoil shapes. We show that an efficient shape representation via parametric level sets can enable online convolutional encoder-decoder application for the shape optimization of hydrofoils. The generalized flow field prediction of the convolutional encoder-decoder is demonstrated by a mean and minimum structural similarity index measure of 0.985 and 0.95, respectively, for predicted solutions compared to {RANS} predictions for out-of-training shapes. The convolutional encoder-decoder predictions are performed nearly five orders of magnitude faster compared to {RANS}. This enables a computationally tractable surrogate-based drag minimization of fifty different hydrofoils for two different design lift coefficients. Furthermore, the best local minimum obtained via the surrogate-based optimization lie in the neighbourhood of the {RANS}-predicted counterparts for both the design lift cases. The present findings show promise for the future shape optimization via parametric level sets with convolutional encoder-decoder over a broader spectrum of flow conditions and shapes.},
	number = {{arXiv}:2301.05597},
	publisher = {{arXiv}},
	author = {Mallik, Wrik and Jaiman, Rajeev K. and Jelovica, Jasmin},
	urldate = {2023-05-03},
	date = {2023-01-13},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2301.05597 [physics]},
	file = {Mallik 等 - 2023 - A parametric level set method with convolutional e.pdf:C\:\\Users\\Administrator\\Zotero\\storage\\LYK9NPCE\\Mallik 等 - 2023 - A parametric level set method with convolutional e.pdf:application/pdf},
}

@article{li_end--end_2023,
	title = {End-to-end Wind Turbine Wake Modelling with Deep Graph Representation Learning},
	volume = {339},
	issn = {03062619},
	url = {http://arxiv.org/abs/2211.13649},
	doi = {10.1016/j.apenergy.2023.120928},
	abstract = {Wind turbine wake modelling is of crucial importance to accurate resource assessment, to layout optimisation, and to the operational control of wind farms. This work proposes a surrogate model for the representation of wind turbine wakes based on a state-of-the-art graph representation learning method termed a graph neural network. The proposed end-to-end deep learning model operates directly on unstructured meshes and has been validated against high-ﬁdelity data, demonstrating its ability to rapidly make accurate 3D ﬂow ﬁeld predictions for various inlet conditions and turbine yaw angles. The speciﬁc graph neural network model employed here is shown to generalise well to unseen data and is less sensitive to over-smoothing compared to common graph neural networks. A case study based upon a real world wind farm further demonstrates the capability of the proposed approach to predict farm scale power generation. Moreover, the proposed graph neural network framework is ﬂexible and highly generic and as formulated here can be applied to any steady state computational ﬂuid dynamics simulations on unstructured meshes.},
	pages = {120928},
	journaltitle = {Applied Energy},
	shortjournal = {Applied Energy},
	author = {Li, Siyi and Zhang, Mingrui and Piggott, Matthew D.},
	urldate = {2023-05-03},
	date = {2023-06},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2211.13649 [cs]},
	file = {Li 等 - 2023 - End-to-end Wind Turbine Wake Modelling with Deep G.pdf:C\:\\Users\\Administrator\\Zotero\\storage\\45Q93SMN\\Li 等 - 2023 - End-to-end Wind Turbine Wake Modelling with Deep G.pdf:application/pdf},
}

@misc{davis_deep_2023,
	title = {Deep learning based surrogate modeling for thermal plume prediction of groundwater heat pumps},
	url = {http://arxiv.org/abs/2302.08199},
	abstract = {The ability for groundwater heat pumps to meet space heating and cooling demands without relying on fossil fuels, has prompted their mass roll-out in dense urban environments. In regions with high subsurface groundwater ﬂow rates, the thermal plume generated from a heat pump’s injection well can propagate downstream, aﬀecting surrounding users and reducing their heat pump eﬃciency. To reduce the probability of interference, regulators often rely on simple analytical models or high-ﬁdelity groundwater simulations to determine the impact that a heat pump has on the subsurface aquifer and surrounding heat pumps. These are either too inaccurate or too computationally expensive for everyday use. In this work, a surrogate model was developed to provide a quick, high accuracy prediction tool of the thermal plume generated by a heat pump within heterogeneous subsurface aquifers. Three variations of a convolutional neural network were developed that accepts the known groundwater Darcy velocities as discrete 2D inputs and predicts the temperature within the subsurface aquifer around the heat pump. A data set consisting of 800 numerical simulation samples, generated from random permeability ﬁelds and pressure boundary conditions, was used to provide pseudo-randomized Darcy velocity ﬁelds as input ﬁelds and the temperature ﬁeld solution for training the network. The subsurface temperature ﬁeld output from the network provides a more realistic temperature ﬁeld that follows the Darcy velocity streamlines, while being orders of magnitude faster than conventional high-ﬁdelity solvers.},
	number = {{arXiv}:2302.08199},
	publisher = {{arXiv}},
	author = {Davis, Kyle and Leiteritz, Raphael and Pflüger, Dirk and Schulte, Miriam},
	urldate = {2023-05-03},
	date = {2023-02-16},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2302.08199 [physics]},
	file = {Davis 等 - 2023 - Deep learning based surrogate modeling for thermal.pdf:C\:\\Users\\Administrator\\Zotero\\storage\\ZYCT4LRG\\Davis 等 - 2023 - Deep learning based surrogate modeling for thermal.pdf:application/pdf},
}

@article{cai_dense_2019,
	title = {Dense motion estimation of particle images via a convolutional neural network},
	volume = {60},
	issn = {0723-4864, 1432-1114},
	url = {http://link.springer.com/10.1007/s00348-019-2717-2},
	doi = {10.1007/s00348-019-2717-2},
	abstract = {In this paper, we propose a supervised learning strategy for the fluid motion estimation problem (i.e., extracting the velocity fields from particle images). The purpose of this work is to design a convolutional neural network ({CNN}) for estimating dense motion field for particle image velocimetry ({PIV}), which allows to improve the computational efficiency without reducing the accuracy. First, the network model is developed based on {FlowNetS}, which is recently proposed for end-to-end optical flow estimation in the computer vision community. The input of the network is a particle image pair and the output is a velocity field with displacement vectors at every pixel. Second, a synthetic dataset of fluid flow images is generated to train the {CNN} model. To our knowledge, this is the first time a {CNN} has been used as a global motion estimator for particle image velocimetry. Experimental evaluations indicate that the trained {CNN} model can provide satisfactory results in both artificial and laboratory {PIV} images. The proposed estimator is also applied to the experiment of turbulent boundary layer. In addition, the computational efficiency of the {CNN} estimator is much superior to those of the traditional cross-correction and optical flow methods.},
	pages = {73},
	number = {4},
	journaltitle = {Experiments in Fluids},
	shortjournal = {Exp Fluids},
	author = {Cai, Shengze and Zhou, Shichao and Xu, Chao and Gao, Qi},
	urldate = {2023-05-03},
	date = {2019-04},
	langid = {english},
	file = {Cai 等 - 2019 - Dense motion estimation of particle images via a c.pdf:C\:\\Users\\Administrator\\Zotero\\storage\\RVUV4CGF\\Cai 等 - 2019 - Dense motion estimation of particle images via a c.pdf:application/pdf},
}

@misc{fischer_flownet_2015,
	title = {{FlowNet}: Learning Optical Flow with Convolutional Networks},
	url = {http://arxiv.org/abs/1504.06852},
	shorttitle = {{FlowNet}},
	abstract = {Convolutional neural networks ({CNNs}) have recently been very successful in a variety of computer vision tasks, especially on those linked to recognition. Optical ﬂow estimation has not been among the tasks where {CNNs} were successful. In this paper we construct appropriate {CNNs} which are capable of solving the optical ﬂow estimation problem as a supervised learning task. We propose and compare two architectures: a generic architecture and another one including a layer that correlates feature vectors at different image locations.},
	number = {{arXiv}:1504.06852},
	publisher = {{arXiv}},
	author = {Fischer, Philipp and Dosovitskiy, Alexey and Ilg, Eddy and Häusser, Philip and Hazırbaş, Caner and Golkov, Vladimir and van der Smagt, Patrick and Cremers, Daniel and Brox, Thomas},
	urldate = {2023-05-03},
	date = {2015-05-04},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1504.06852 [cs]},
	file = {Fischer 等 - 2015 - FlowNet Learning Optical Flow with Convolutional .pdf:C\:\\Users\\Administrator\\Zotero\\storage\\VSYAGYPS\\Fischer 等 - 2015 - FlowNet Learning Optical Flow with Convolutional .pdf:application/pdf},
}

@misc{yu_back_2016,
	title = {Back to Basics: Unsupervised Learning of Optical Flow via Brightness Constancy and Motion Smoothness},
	url = {http://arxiv.org/abs/1608.05842},
	shorttitle = {Back to Basics},
	abstract = {Recently, convolutional networks (convnets) have proven useful for predicting optical ﬂow. Much of this success is predicated on the availability of large datasets that require expensive and involved data acquisition and laborious labeling. To bypass these challenges, we propose an unsupervised approach (i.e., without leveraging groundtruth ﬂow) to train a convnet end-to-end for predicting optical ﬂow between two images. We use a loss function that combines a data term that measures photometric constancy over time with a spatial term that models the expected variation of ﬂow across the image. Together these losses form a proxy measure for losses based on the groundtruth ﬂow. Empirically, we show that a strong convnet baseline trained with the proposed unsupervised approach outperforms the same network trained with supervision on the {KITTI} dataset.},
	number = {{arXiv}:1608.05842},
	publisher = {{arXiv}},
	author = {Yu, Jason J. and Harley, Adam W. and Derpanis, Konstantinos G.},
	urldate = {2023-05-03},
	date = {2016-08-20},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1608.05842 [cs]},
	file = {Yu 等 - 2016 - Back to Basics Unsupervised Learning of Optical F.pdf:C\:\\Users\\Administrator\\Zotero\\storage\\A8XHI8R6\\Yu 等 - 2016 - Back to Basics Unsupervised Learning of Optical F.pdf:application/pdf},
}

@misc{meister_unflow_2017,
	title = {{UnFlow}: Unsupervised Learning of Optical Flow with a Bidirectional Census Loss},
	url = {http://arxiv.org/abs/1711.07837},
	shorttitle = {{UnFlow}},
	abstract = {In the era of end-to-end deep learning, many advances in computer vision are driven by large amounts of labeled data. In the optical ﬂow setting, however, obtaining dense perpixel ground truth for real scenes is difﬁcult and thus such data is rare. Therefore, recent end-to-end convolutional networks for optical ﬂow rely on synthetic datasets for supervision, but the domain mismatch between training and test scenarios continues to be a challenge. Inspired by classical energy-based optical ﬂow methods, we design an unsupervised loss based on occlusion-aware bidirectional ﬂow estimation and the robust census transform to circumvent the need for ground truth ﬂow. On the {KITTI} benchmarks, our unsupervised approach outperforms previous unsupervised deep networks by a large margin, and is even more accurate than similar supervised methods trained on synthetic datasets alone. By optionally ﬁne-tuning on the {KITTI} training data, our method achieves competitive optical ﬂow accuracy on the {KITTI} 2012 and 2015 benchmarks, thus in addition enabling generic pre-training of supervised networks for datasets with limited amounts of ground truth.},
	number = {{arXiv}:1711.07837},
	publisher = {{arXiv}},
	author = {Meister, Simon and Hur, Junhwa and Roth, Stefan},
	urldate = {2023-05-03},
	date = {2017-11-21},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1711.07837 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Meister 等 - 2017 - UnFlow Unsupervised Learning of Optical Flow with.pdf:C\:\\Users\\Administrator\\Zotero\\storage\\3MZ6KBQ8\\Meister 等 - 2017 - UnFlow Unsupervised Learning of Optical Flow with.pdf:application/pdf},
}
